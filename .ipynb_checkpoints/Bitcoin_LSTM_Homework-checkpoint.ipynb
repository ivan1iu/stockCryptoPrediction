{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7317ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, LSTM\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# ISE 537 - Homework 4, Problem 2: Bitcoin Price Prediction using LSTM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c6d62b",
   "metadata": {},
   "source": [
    "# Step 1: Load and Clean Bitcoin Data\n",
    "\n",
    "**Note:** The data has duplicate observations at each timestamp. We need to clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8be61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Bitcoin data\n",
    "df = pd.read_csv('Bitcoin_Price__1_.csv')\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb708c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Number of unique timestamps: {df['datetime'].nunique()}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"\\nDuplicates per timestamp: {len(df) / df['datetime'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd6a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data by averaging duplicate observations\n",
    "df_clean = df.groupby('datetime')['price'].mean().reset_index()\n",
    "print(f\"Cleaned data shape: {df_clean.shape}\")\n",
    "print(f\"\\nCleaned data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a0ca5c",
   "metadata": {},
   "source": [
    "# Step 2: Visualize Bitcoin Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64be09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Bitcoin Price History')\n",
    "plt.plot(df_clean['price'])\n",
    "plt.xlabel('Time', fontsize=18)\n",
    "plt.ylabel('Bitcoin Price USD ($)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f9640",
   "metadata": {},
   "source": [
    "# Step 3: Prepare Data for LSTM\n",
    "\n",
    "**Homework Requirements:**\n",
    "- Normalize to [0, 1] using MinMaxScaler ✓\n",
    "- 80% training, 20% testing (NOT 95%/5%) ✓\n",
    "- Lookback window = 10 (NOT 60) ✓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the price data\n",
    "data = df_clean.filter(['price'])\n",
    "dataset = data.values\n",
    "\n",
    "# Get the number of rows to train the model on (80% for training)\n",
    "training_data_len = int(np.ceil(len(dataset) * 0.80))  # Changed from 0.95 to 0.80\n",
    "\n",
    "print(f\"Total data points: {len(dataset)}\")\n",
    "print(f\"Training data length: {training_data_len} ({training_data_len/len(dataset)*100:.1f}%)\")\n",
    "print(f\"Testing data length: {len(dataset) - training_data_len} ({(1-training_data_len/len(dataset))*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f5ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to [0, 1]\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "print(f\"Data normalized. Min: {scaled_data.min():.4f}, Max: {scaled_data.max():.4f}\")\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data set with lookback window = 10 (changed from 60)\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "lookback = 10  # Changed from 60 to 10\n",
    "\n",
    "for i in range(lookback, len(train_data)):\n",
    "    x_train.append(train_data[i-lookback:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "        \n",
    "# Convert to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape the data for LSTM [samples, time steps, features]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06978d0",
   "metadata": {},
   "source": [
    "# Step 4: Build LSTM Model\n",
    "\n",
    "**Homework Specifications:**\n",
    "- LSTM layer: 4 units (NOT 128 and 64)\n",
    "- Dense layer: 1 unit\n",
    "- Optimizer: Adam\n",
    "- Loss: Mean Squared Error\n",
    "- Batch size: 256\n",
    "- Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model (as specified in homework)\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(x_train.shape[1], 1)))  # Changed from 128 to 4\n",
    "model.add(Dense(1))  # Single output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fff543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100, verbose=2, validation_split=0.1)\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04774779",
   "metadata": {},
   "source": [
    "# Step 5: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the testing data set\n",
    "test_data = scaled_data[training_data_len - lookback:, :]\n",
    "\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "\n",
    "for i in range(lookback, len(test_data)):\n",
    "    x_test.append(test_data[i-lookback:i, 0])\n",
    "    \n",
    "# Convert to numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape the data\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72833ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "train_predictions = model.predict(x_train)\n",
    "test_predictions = model.predict(x_test)\n",
    "\n",
    "# Inverse transform to get actual prices\n",
    "train_predictions = scaler.inverse_transform(train_predictions)\n",
    "test_predictions = scaler.inverse_transform(test_predictions)\n",
    "\n",
    "print(\"Predictions completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e26d3eb",
   "metadata": {},
   "source": [
    "# Question (a): Calculate RMSE and Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE for training set\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train.reshape(-1, 1), \n",
    "                                         scaler.inverse_transform(y_train.reshape(-1, 1)),\n",
    "                                         scaler.inverse_transform(model.predict(x_train))))\n",
    "train_rmse = np.sqrt(np.mean((scaler.inverse_transform(model.predict(x_train)) - \n",
    "                               scaler.inverse_transform(y_train.reshape(-1, 1))) ** 2))\n",
    "\n",
    "# Calculate RMSE for testing set  \n",
    "test_rmse = np.sqrt(np.mean((test_predictions - y_test) ** 2))\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"QUESTION (a): RMSE Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTraining RMSE: ${train_rmse:.2f}\")\n",
    "print(f\"Testing RMSE: ${test_rmse:.2f}\")\n",
    "print(f\"\\nTest/Train RMSE Ratio: {test_rmse/train_rmse:.3f}\")\n",
    "\n",
    "# Calculate percentage errors\n",
    "train_mean_price = scaler.inverse_transform(y_train.reshape(-1, 1)).mean()\n",
    "test_mean_price = y_test.mean()\n",
    "print(f\"\\nTraining RMSE as % of mean price: {(train_rmse/train_mean_price)*100:.2f}%\")\n",
    "print(f\"Testing RMSE as % of mean price: {(test_rmse/test_mean_price)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c4137",
   "metadata": {},
   "source": [
    "## Answer to Question (a):\n",
    "\n",
    "**Training RMSE:** [See output above]\n",
    "\n",
    "**Testing RMSE:** [See output above]\n",
    "\n",
    "**Is the performance satisfactory?**\n",
    "\n",
    "[Write your analysis based on the RMSE values - if they're < 5% of mean price, performance is excellent]\n",
    "\n",
    "**Is there evidence of overfitting?**\n",
    "\n",
    "[Analyze the Test/Train RMSE ratio:\n",
    "- If ratio < 1.2: No significant overfitting\n",
    "- If ratio 1.2-1.5: Mild overfitting  \n",
    "- If ratio > 1.5: Significant overfitting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9b918",
   "metadata": {},
   "source": [
    "# Question (b): Plot True vs Predicted Prices\n",
    "\n",
    "Plot the last 1/3 of training period + all of testing period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a80732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "train_data_plot = data[:training_data_len]\n",
    "train_predictions_plot = np.empty_like(data)\n",
    "train_predictions_plot[:, :] = np.nan\n",
    "train_predictions_plot[lookback:training_data_len, :] = scaler.inverse_transform(model.predict(x_train))\n",
    "\n",
    "test_predictions_plot = np.empty_like(data)\n",
    "test_predictions_plot[:, :] = np.nan\n",
    "test_predictions_plot[training_data_len:len(dataset), :] = test_predictions\n",
    "\n",
    "# Calculate indices for last 1/3 of training\n",
    "train_plot_start = training_data_len - (training_data_len - lookback) // 3\n",
    "\n",
    "print(f\"Plotting from index {train_plot_start} to {len(dataset)}\")\n",
    "print(f\"Last 1/3 of training: {training_data_len - train_plot_start} points\")\n",
    "print(f\"Testing period: {len(dataset) - training_data_len} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plot true prices\n",
    "plt.plot(data.index[train_plot_start:training_data_len], \n",
    "         data[train_plot_start:training_data_len], \n",
    "         label='True Price (Training)', color='blue', linewidth=2, alpha=0.7)\n",
    "\n",
    "plt.plot(data.index[training_data_len:], \n",
    "         data[training_data_len:], \n",
    "         label='True Price (Testing)', color='green', linewidth=2, alpha=0.7)\n",
    "\n",
    "# Plot predicted prices\n",
    "plt.plot(data.index[train_plot_start:training_data_len], \n",
    "         train_predictions_plot[train_plot_start:training_data_len], \n",
    "         label='Predicted Price (Training)', color='cyan', linewidth=2, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.plot(data.index[training_data_len:], \n",
    "         test_predictions_plot[training_data_len:], \n",
    "         label='Predicted Price (Testing)', color='red', linewidth=2, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add vertical line at train/test split\n",
    "plt.axvline(x=data.index[training_data_len], color='black', linestyle=':', linewidth=2, \n",
    "            label='Train/Test Split')\n",
    "\n",
    "plt.xlabel('Time Step', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Bitcoin Price ($)', fontsize=12, fontweight='bold')\n",
    "plt.title('Bitcoin Price Prediction using LSTM\\n(Last 1/3 of Training Period + Testing Period)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37bed9",
   "metadata": {},
   "source": [
    "## Answer to Question (b):\n",
    "\n",
    "**Does the performance look good on the plot?**\n",
    "\n",
    "[Analyze the plot:\n",
    "- How closely do predicted prices track true prices?\n",
    "- Does the model capture trends and volatility?\n",
    "- Is there a drop in performance at the train/test boundary?\n",
    "- Overall assessment of visual performance]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfed483",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "**Model Configuration:**\n",
    "- Lookback window: 10\n",
    "- Training/Testing split: 80/20\n",
    "- LSTM units: 4\n",
    "- Batch size: 256\n",
    "- Epochs: 100\n",
    "\n",
    "**Key Results:**\n",
    "- Training RMSE: [value]\n",
    "- Testing RMSE: [value]\n",
    "- Performance assessment: [excellent/satisfactory/needs improvement]\n",
    "- Overfitting: [none/mild/significant]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
